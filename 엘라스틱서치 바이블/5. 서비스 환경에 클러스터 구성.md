
이번 챕터에서는 엘라스틱서치를 실제 서비스 환경에 도입해 사용하기 위한 주요 설정과 클러스터 구성 전략을 학습합니다.


## 1. 운영 환경을 위한 설정과 클러스터 구성

#### 1) 노드 설정과 노드 역할

##### 노드 역할
엘라스틱서치 노드에는 역할이라는 개념이 있습니다. 클러스터 구성을 위해서는 반드시 노드에 역할을 지정해야 합니다.

- 마스터 후보 노드
	- 노드의 역할에 master를 지정하면 해당 노드는 마스터 후보 노드가 됩니다. 
	- 마스터 후보 노드 중에서 선거를 통해 마스터 노드가 설출됩니다. 
	- 마스터 노드는 클러스터를 관리하는 역할을 수행합니다. 
	- 인덱스 생성이나 삭제, 어떤 샤드를 어느 노드에 할당할 것인지 등 중요한 작업을 수행합니다.

- 데이터 노드
	- 실제 데이터를 들고 있는 노드입니다.
	- CRUD, 검색, 집계와 같은 데이터와 관련된 작업을 수행합니다.

- 인제스트 노드
	- 데이터가 색인되기 전에 전처리를 수행하는 인제스트 파이프라인을 수행하는 노드입니다.

- 조정 노드
	- 클라이언트의 요청을 받아서 다른 노드에 요청을 분배하고 클라이언트에게 최종 응답을 돌려주는 노드를 조정 노드라고 합니다.
	- 기본적으로는 모든 노드가 조정 역할을 수행합니다.
	- 마스터나 데이터 등 중요 역할을 수행하지 않고 조정 역할만 수행하는 노드는 조정 전용 노드라고 합니다.

- 원격 클러스터 클라이언트 노드
	- 다른 엘라스틱서치 클러스터에 클라이언트로 붙을 수 있는 노드입니다.
	- 노드 역할에 remote_cluster_client를 추가해 지정합니다.
	- 키바나의 스택 모니터링 기능을 활용해서 모니터링 전용 클러스터를 구축한 뒤 얼럿 메시지를 보내도록 구성하거나 유료 기능인 클러스터 간 검색 기능 등을 활용할 때 사용됩니다.

- 데이터 티어 노드
	- 데이터 노드를 용도 및 성능별로 hot-warm-cold-frozen 티어로 구분해 저장하는 데이터 티어 구조 채택 시 사용하는 역할입니다.
	- data 역할 대신에 data_contetn, data_hot, data_warm, data_cold, data_frozen 역할을 선택합니다.


> 위 역할 외에도 기계 학습이나 피벗 변환 등 몇몇 특수 기능을 위한 전용 역할이 있습니다.

##### config/elasticsearch.yml

개발 모드와 다르게 discovery.type: "single-node" 가 없어집니다. 아래에 각각의 설정에 대해 설명하겠습니다.

- node.roles
	- 노드 역할을 지정하는 설정입니다.
	- node.roles: \[] 와 같이 비워 두면 조정 전용 노드가 됩니다.
	- 서비스 환경에서는 마스터 후보 역할과 데이터 역할을 분리해야 좋은 경우가 많습니다.
- discovery.seed_hosts
	- 마스터 노드로 동작할 수 있는 노드 목록을 지정합니다.
- cluster.initial_master_nodes
	- 클러스터를 처음 기동할 때 첫 마스터 선거를 수행할 후보 노드 목록을 지정합니다.
	- 이 값은 node.name에 기입한 값이어야 합니다.
- network.bind_host와 network.publish_host
	- network.bind_host는 엘라스틱서치에 바인딩할 네트워크 주소를 지정합니다.
	- network.publish_host는 클러스터의 다른 노드에게 자신을 알릴 때 쓰는 주소를 지정합니다.
- http.port
	- HTTP 통신을 위해 사용하는 포트를 지정합니다. 
	- 기본값은 9200-9300 입니다.
	- 이렇게 범위를 지정하면 범위 내의 선점되지 않은 포트 중 가장 앞쪽 포트를 사용합니다.
- transport.port
	- transport 통신을 위해 사용하는 포트를 지정합니다.
	- 기본값은 9300-9400 입니다.
	- transport 프로토콜은 엘라스틱서치의 노드 사이의 내부 통신에 사용되는 프로토콜입니다.
- path.data
	- 데이터 디렉터리의 경로를 지정할 수 있습니다.

##### 그 외 필요한 주요 설정

\1) 힙 크기
적절한 힙 크기 지정이 중요합니다. 힙 크기는 config/jvm.options를 열어 설정할 수 있습니다. 7.11 버전 이상 사용 시 config/jvm.options 파일을 직접 수정하는 것보다는 config/jvm.options.d 디렉터리 밑에 별도 파일을 새로 생성해서 힙 크기를 지정하는 것이 관리가 편합니다.

힙 크기는 각 운영 환경에 맞는 적절한 크기로 지정하는 것이 중요합니다.
- 힙 크기 설정의 가장 우선인 첫 번째 대원칙은 최소한 시스템 메모리의 절반 이하로 지정해야 한다는 것입니다. 시스템 메모리의 절반은 운영체제가 캐시로 쓰도록 놔두는 것이 좋습니다.
- 그 다음 두 번째 대원칙은 힙 크기를 32GB 이상 지정하지 않아야 한다는 것입니다.

> 32GB 이내의 힙 영역에만 접근한다면 Compressed OOPs 라는 기능을 적용해 포인터를 32비트로 유지할 수 있습니다.
> 다만 힙 메모리의 시작 주소는 0부터 시작하지 않습니다. 따라서 실제로 Compressed OOPs 기능이 적용되는 힙 크기의 경곗값은 32GB보다 살짝 아래쪽입니다.

그렇다면 힙 크기를 얼마로 지정해야 할까??
일반적으로는 Zero-based Compressed OOPs 까지도 적용되는 선까지 내려서 설정하는 편이 성능상 더 낫지만, 반드시 그렇지는 않습니다.
이것저것 따질 만한 여유가 없거나 엄밀한 테스트가 힘든 상황이라면 속 편하게 Zero-based 선까지 낮추기를 권장합니다. 일단 최소한 Compressed OOPs는 적용되도록 힙 크기를 지정해야 합니다.


\2) 스와핑
엘라스틱서치는 스와핑을 사용하지 않도록 강력히 권고합니다. 스와핑은 성능과 노드 안정성에 큰 영향을 미칩니다. 엘라스틱서치 공식 문서에서는 스와핑을 켜느니 차라리 운영체제가 노드를 kill 시키도록 놔두는 것이 낫다고 가이드하고 있습니다.

스와핑을 완전히 끄기 위해 여러 방법이 있지만 아래 소개하는 방법이 가장 좋습니다.

```
sudo swapoff -a
```

운영체재 재부팅 이후에도 스와핑 비활성화 상태를 유지하고 싶으면 다음과 같이 /etc/fstab 을 수정하여 swap 부분을 제거해야 합니다.


\3) vm.max_map_count
vm.max_map_count 값은 프로세스가 최대 몇 개까지 메모리 맵 영역을 가질 수 있는지를 지정합니다. 루씬은 mmap을 적극적으로 활용하기 때문에 vm.max_map_count 값을 높일 필요가 있습니다. 이 값을 영구적으로 설정하려면 스와핑 설정 때와 마찬가지로 /etc/sysctl.d 밑에 적절한 conf 파일을 하나 만들어서 설정을 넣어야 합니다.

```
sudo vim /etc/sysctl.d/98-elasticsearch.conf

vm.max_map_count=262144
```

vm.max_map_count 값은 최대치를 규정할 뿐이며 이 값을 더 높여 설정하더라도 운영체제상 실제 메모리 사용량이나 성능상 손해는 없다고 알려져 있습니다. 따라서 시스템 메모리에 여유가 있다면 vm.max_map_count를 262144 보다 좀 더 높여서 지정해도 문제가 없습니다.

> 실제로 대부분의 경우 262144로 지정해 대규모 엘라스틱서치 서비스를 운영해도 별문제는 없습니다.


\4) 파일 기술자
엘라스틱서치는 많은 파일 기술자(file descriptor)를 필요로 합니다. 엘라스틱서치는 이 값을 최소 65535 이상으로 지정하도록 가이드합니다.

영구적으로 지정하기 위해서는 /etc/security/limits.conf 를 수정해야 합니다.

```
sudo vim /etc/security/limits.conf

username - nofile 65535
```

위와 같이 엘라스틱서치 프로세스를 기동하는 유저 이름을 넣고 nofile을 65535로 지정하면 됩니다.


\5) JVM 지정과 설정

특별한 사유가 없다면 내장 JDK를 사용하는 것이 좋으며 힙 크기 위의 JVM 설정을 굳이 변경하지 않도록 권고하는 부분 역시 마찬가지 입니다.

> 일반적인 서비스 운영 상황에서는 대부분은 특별히 건드릴 필요가 없습니다.


---

## 2. 클러스터 구성 전략

#### 1) 마스터 후보 노드와 데이터 노드를 분리

어느 정도 규모가 있는 서비스를 위해 클러스터를 운영한다면 마스터 후보 노드를 데이터 노드와 분리시켜야 합니다. 마스터 노드는 클러스터를 관리하는 중요한 역할을 수행합니다. 엘라스틱서치 운영에서 발생할 수 있는 여러 가지 문제를 보면 상대적으로 데이터 노드가 죽을 확률이 높습니다.

만약 이러한 문제 상황 시 마스터 역할과 데이터 역할을 분리해 두지 않았다면 마스터 역할이 제대로 수행되지 않아 클러스터 안정성이 매우 크게 떨어지게 됩니다. 일부 데이터 노드에만 문제가 생기는 것으로 끝날 수 있었을 상황이 클러스터 전체 장애 상황으로 커지게 됩니다.

> 따라서 서버를 매우 적게 써야 하는 상황이 아니라면 마스터 후보 노드와 데이터 노드를 분리하는 것이 낫습니다.

마스터 후보 노드는 데이터 노드보다 상대적으로 성능이 많이 낮은 서버를 사용해도 괜찮습니다. 데이터 노드처럼 디스크를 많이 사용하거나 메모리를 많이 필요로 하지 않습니다. 실제 물리 장비가 아니라 사양이 낮은 가상 서버를 이용해도 문제가 없습니다. 반대로 성능이 좋은 장비에는 데이터 노드 역할을 주는 것이 좋습니다. 만약 마스터 후보 노드에 가상 서버를 사용한다면 마스터 후보 노드들이 같은 실제 물리 장비에 배정되지 않도록 체크해야 합니다.

#### 2) 마스터 후보 노드와 투표 구성원

마스터 노드를 선출하는 집단이 바로 투표 구성원입니다. 투표 구성은 마스터 후보 노드 중 일부 혹은 전체로 구성된 마스터 후보 노드의 부분 집합으로 마스터 선출이나 클러스터 상태 저장 등의 의사결정에 참여하는 노드의 모임입니다. 일반적으로는 마스터 후보 노드와 동일한 집합입니다.

투표 구성원의 절반 이상이 동시에 멈추면 클러스터는 의사결정을 내릴 수 없는 상황에 빠지게됩니다. 마스터 후보 노드는 홀수대를 준비하는 것이 비용 대비 효용성이 좋습니다.

#### 3) 서버 자원이 많지 않은 경우

적어도 노드 3대가 확보돼야 클러스터를 구성하는 의미가 있습니다. 마스터 후보 역할을 하는 노드가 최소 3대, 데이터 역할을 하는 노드가 최소 3대 확보돼야 기본적인 고가용성이 제공되기 때문입니다.

- 최소 구성 장비 3대
	3대의 노드가 모두 마스터 후보 역할과 데이터 역할을 겸임하는 구성이 됩니다. 이 구성은 마스터와 데이터 역할을 완전히 겸임하기 때문에 안정성이 좋은 구성은 아니지만 적은 데이터로 소규모 서비스에 엘라스틱서치를 도입한다면 이 구성으로도 서비스가 가능합니다. 장비가 3대이면 숫자상 완전히 겸임하는 방법뿐입니다.

- 사양이 낮은 장비 4~5대가 있는 경우
	 3대는 마스터 후보 역할과 데이터 역할을 겸임하게 지정하고 나머지 1~2대를 데이터 노드 전용으로 지정합니다.

- 사양이 높은 장비 4~5대가 있는 경우
	 변경할 수 있다면 사양이 낮은 장비 3대에 마스터 후보 역할을 주고 사양이 높은 나머지 장비에 데이터 노드 역할을 줍니다.

- 장비 6~7대
	 장비 6대부터는 마스터 후보 노드와 데이터 노드를 완전히 분리할 수 있습니다. 따라서 일반적으로는 분리하는 편이 서비스 안정성 면에서 훨씬 이득입니다.

#### 4) 서버 자원이 굉장히 많이 필요한 경우

한 클러스터에 동원해야 하는 물리 서버가 200대 이상인 경우 등 서비스 요건이 빠듯하고 동원할 수 있는 서버 자원이 굉장히 많은 상황이 있습니다. 이런 상황에는 먼저 용도나 중요도별로 클러스터를 더 잘게 쪼갤 수 있는지 검토해야 합니다. 기본적으로 선출되는 마스터 노드는 클러스터당 한 대라는 점을 의식하고 있어야 합니다.

이런 경우 앞서 다뤘던 다른 경우들과는 달리 마스터 후보 노드도 높은 사양의 서버로 준비하는 것이 좋습니다. 그리고 마스터 노드에 부담이 갈 만한 작업을 피하도록 설계해야 합니다. 그래도 한계는 있습니다. 노드의 수가 더 늘어나야 한다면 서비스 구조의 복잡도와 관리 비용을 더 높이더라도 강제로 클러스터를 여러 개로 찢어야 합니다. 같은 데이터의 싱크를 맞추고 있는 클러스터를 여러 개 구성한 다음 앞단에서 로드 밸런싱을 하는 전략, 클러스터별로 데이터를 샤딩하는 전략, 클러스터 간 검색 도입 등도 고려해야 합니다.

#### 5) 사양이 크게 차이나는 서버 자원을 활용해야 하는 경우

가용한 서버 자원 사이의 사양 차이가 크다면 같은 운영 비용으로 성능 차이가 적은 서버로 일원화해서 교체 운영할 수 있는지 먼저 검토하는게 좋습니다. 만약 그것이 어려운 상황이고 성능 차이가 좀 나더라도 남은 서버 자원을 긁어모아 활용해야 한다면 데이터 티어 구조의 도입을 고려할 수 있습니다.

성능이 높은 서버를 data_content와 data_hot 역할로, 성능이 낮은 서버를 data_warm, data_cold, data_frozen 역할로 지정합니다. 이후 인덱스 생명 주기 관리 정책을 도입해 오래된 시계열 데이터 인덱스를 낮은 티어의 노드로 이동시키며 운영하는 방법입니다.

> data_hot 노드에 배정된 인덱스를 data_warm으로 이동하는 것 역시 작업이며 클러스터에 부하를 줍니다. 이는 데이터 티어 구조를 채택하지 않았다면 굳이 수행이 필요없었을 추가 작업입니다. 상황을 잘 판단해 신중하게 설계를 해야합니다.

#### 6) 조정 전용 노드

안정적인 클러스터 운영을 위해서는 조정 전용 노드를 두는 것이 좋습니다. 조정 전용 노드는 노드 역할을 node.roles: \[] 로 지정해 조정 역할만을 수행하는 노드입니다. 각 데이터 노드에서 작업한 결과물을 모아서 돌려주는 작업은 생각보다 큰 부하를 줄 수 있습니다. 특히 문제가 되는 부분이 키바나입니다.

키바나는 여러 장애 상황의 원흉이 될 수 있습니다. 키바나가 조정 전용 노드만을 바라보게 설정하고 키바나 외에도 엘라스틱서치의 REST API를 호출해서 읽기 및 쓰기 작업을 수행하는 외부 클라이언트 역시 모니터링용 툴을 제외하면 모두 조정 전용 노드를 바라보도록 설계하는 것이 좋습니다. 엘라스틱서치에 심각한 요청이 인입되기 시작할 때 이 조정 노드를 내리면 최악의 상황으로 번지는 것을 막을 수 있습니다.

> 조정 전용 노드는 어차피 데이터를 들고 있지 않기 때문에 샤드 복구와 관련된 걱정도 없습니다. 부담없이 프로세스를 kill 시킬 수 있습니다.

서버 자원에 여유가 좀 더 있다면 읽기 작업을 담당하는 조정 전용 노드와 쓰기 작업을 담당하는 조정 전용 노드를 분리하는 것도 좋은 방법입니다. 조정 전용 노드는 데이터 노드보다 사양이 낮은 장비로 구성해도 문제가 없습니다. 또한 엘라스틱서치 7 버전 이상부터 도입된 실제 메모리 서킷 브레이커가 이 조정 전용 노드와 궁합이 좋습니다. 조정 전용 노드의 메모리 사용량이 높아지면 서킷 브레이커가 해당 요청을 차단합니다. 다만 무거운 집계 작업이 주가 되는 클러스터라면 조정 전용 노드도 좋은 사양의 장비로 구성하는 것이 좋습니다.

#### 7) 한 서버에 여러 프로세스 띄우기

128GB 이상의 메모리를 사용하는 서버에서 약 32GB 정도의 힙을 설정한 엘라스틱서치 프로세스를 여러 개 띄우는 방법이 있습니다. 먼저 마스터 후보 역할을 하는 프로세스는 다중 프로세스 대상으로 고려하지 말아야 합니다. 클러스터 안정성이 크게 떨어지기 때문입니다. 한 서버에 여러 프로세스를 띄우는 대상은 데이터 노드여야 합니다.

프로세스 기동을 위해서는 반드시 cluster.routing.allocation.same_shard.host: true 설정을 지정해야 합니다. 다중 프로세스 기동을 위해서는 운영자가 알아야 할 사항이 많으며 관리 비용 또한 증가합니다. 다중 프로세스 구성을 통해 성능이 실제로 향상되는지, 높아진 관리 비용을 감수할 만큼 성능이 향상되는지 꼭 사전에 테스트하고 클러스터를 구성하는 것이 좋습니다.


